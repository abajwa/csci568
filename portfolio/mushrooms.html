<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head> 
<title>Application: The Classic Mushroom Dataset</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="author" content="" />
<meta http-equiv="content-type" content="text/html;charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<link rel="stylesheet" href="css/blueprint/screen.css" type="text/css" media="screen, projection" />
<link rel="stylesheet" href="css/blueprint/print.css" type="text/css" media="print" />
<link rel="stylesheet" href="css/main.css" type="text/css" media="screen" /> 
<!--[if IE]>
  <link rel="stylesheet" href="css/blueprint/ie.css" type="text/css" media="screen, projection">
<![endif]-->
</head>
<body>
<div class="container">
  <h1>Data Mining Portfolio</h1>
  <h2>Application: The Classic Mushroom Dataset</h2>

  <p class="summaryStats">
    <u>Can you generate summary statistics that help describe the data? </u>
    <br />
    <br />

    The first thing I did was put the data into Knime to generate the statistics which didn’t give me much in terms of results. One statistic I was able to display were the counts of each part of each attribute. For example, poisonous vs. edible mushrooms; there are more edible mushrooms (approximately 51.8% or 4208 mushrooms) in this dataset than there are poisonous (approximately 48.2% or 3916 mushrooms). For the dataset in general it is hard to generate summary statistics that describe the data, besides the counts. The reason it is hard to do this is because the data is nominal. But, the data can only be changed into binary. Since it either it does or it doesn’t have grooves in its cap-surface, for example. I decided to use a column transform called One2Many. This transform split up the data into many binary columns so that I could try running the summary statistics on it once again. So at this point the data has a separate column for each value of each attribute. The statistics generated with these new columns didn’t really help much either. They do show the number of mushrooms per feature, but I had that information before and since they’re binary the min and max don’t matter. Also, the standard deviation and variance aren’t all that useful. At this point, due to the features of the data, I think it’s safe to conclude that interesting summary statistics that describe this data cannot be generated.

    <br />

    <center>
    <img src="images/counts.png"/>
    <br />
    <br />
    Figure 1. Counts for the poisonous vs. edible
    </center>
    <br />
  </p>

  <p class="grouping">
    <u>Can the edible and poisonous data objects be distilled into groups?</u>
    <br />
    <br />

    For this question, my first thought was to try to cluster the data since clustering is essentially distilling data objects into groups. My mind automatically went to the K-means clustering algorithm. I already have the data loaded into Knime so I tried adding the k-means node to the workspace and connecting it to the csv reader node but that wasn’t working. Knime gave me a warning that says “No columns in include list! Produces one huge cluster.” I tried to edit the settings but since the attributes are nominal it wouldn’t let me add those to the list. I figured out how to add the Weka plugin for Knime so that I could use Weka nodes which do allow K-means to be used on nominal data. The SimpleKMeans node from Weka didn’t have this issue. I specified 2 clusters, hoping it would cluster poisonous in one and edible in another. This did not do so well. I got two clusters with 38% of the data in one and 62% in the other. I know from question 1 that the distribution of poisonous vs. edible is a little more even than that. I also tried this with the binary data and ended up with the same results. At this point I switched over to Weka and tried a SimpleKMeans with it ignoring the poisonous attribute. This actually distributed the data closer to the counts in problem 1 but, as you can see in Figure 2, it did not cluster the edible in one group and poisonous in the other, which was the idea of clustering it. I also spent a little bit of time trying to hierarchically cluster the data and use DBSCAN on it. These algorithms also resulted in no luck. At this point I do not think the data can be distilled into groups. 

    <br />
    <br />
    <center>
    <img src="images/SimpleKMeans.png"/>
    <br />
    <br />
    Figure 1. K-means clusters
    </center>
    <br />
  </p>
  <p class="modeling">
    <u>Can a classification model be created that can predict whether a mushroom is edible or poisonous?</u>
    <br />
    <br />

    When I first began this problem I went through a couple different options of classification in my head. I thought about trying a decision tree, nearest neighbor, and a rule based classifier. I decided on a decision tree because the data has already been made binary and, hopefully, this can predict whether a mushroom is edible or poisonous based on different attributes. At this point I added a decision tree learner node and connected it to the CSV Reader node since the Decision Tree Learner node can deal with the nominal attributes. I configured the node to use the first column as the class name and use gini impurity to compare different attribute test conditions. The decision tree actually generated a pretty good classification (See Figure 3). The topmost decision was based on column 5 which is the odor of the mushroom. Using just the discrete values of this column most of the data was split into poisonous or edible with 100% purity. The only value it did not cleanly separate was an odor of None which had 96.6% edible and 3.4% poisonous. After this, the next split was on column 20, which is the spore-print-color, with the value of w which is white. After this point the data was split a couple more times in order to achieve 100% purity in each of the leaf nodes of the tree. A decision tree model can be created that predicts whether a mushroom is poisonous or edible.

    <br />
    <center>
    <img src="images/decisionTree.png" width="782" height="311"/>
    <br />
    <br />
    Figure 3. Decision Tree
    </center>
  </p>

  <p class="anomalies">
    <u>Do any anomalies exist in the dataset?</u>
    <br />
    <br />

    This question is a tough one to answer. First of all, from the decision tree, it seems like an attribute of poisonous when a mushroom has no odor is an anomaly since there are 3,408 that are edible and only 120 that are poisonous. But this may not always be the case since there are variations in nature. Also, according to the Meta data, the mushrooms whose poisonous status is unknown are classified as poisonous so this may be affecting the data. While I was conducting the clustering and classification algorithms above I tried to look for anomalies but they weren’t obvious in the dataset. I think it is safe to conclude that the values found to be somewhat anomalous may be natural variations and it is not possible to conclude certain values as anomalies.
  </p>
  
  <p class="association">
    <u>Can any association rules be generated from this dataset?</u>
    <br />
    <br />
    For this problem, I decided to try the A Priori approach to generating rules. This required the Weka plug-in for Knime. I added the Apriori node to the CSV Reader node and ran the algorithm on the data looking for the 10 best rules. All of the rules generated had a confidence of one (See Figure 4). I tried this algorithm with a higher number of rules and all of them ended up with a confidence of one. So, any number of rules can be generated. Also, the Meta data file contains a set of rules that work fairly well for the dataset. Yes, association rules can be generated from this dataset.

    <br />
    <center>
    <img src="images/aPrioriResults.png"/>
    <br />
    <br />
    Figure 4. A Priori Rules generated by Weka
    </center>
  </p>
</div>
</body>
</html>